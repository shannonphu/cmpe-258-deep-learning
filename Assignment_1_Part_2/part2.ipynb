{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "part2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXTIClG-cxH2"
      },
      "source": [
        "BATCH_SIZE = 128\r\n",
        "EPOCHS = 10\r\n",
        "\r\n",
        "training_images_file   = 'gs://mnist-public/train-images-idx3-ubyte'\r\n",
        "training_labels_file   = 'gs://mnist-public/train-labels-idx1-ubyte'\r\n",
        "validation_images_file = 'gs://mnist-public/t10k-images-idx3-ubyte'\r\n",
        "validation_labels_file = 'gs://mnist-public/t10k-labels-idx1-ubyte'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Cp5WpIWjnis"
      },
      "source": [
        "import os, re, math, json, shutil, pprint\r\n",
        "import PIL.Image, PIL.ImageFont, PIL.ImageDraw\r\n",
        "import IPython.display as display\r\n",
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuB4V0rsjpCI"
      },
      "source": [
        "AUTO = tf.data.experimental.AUTOTUNE\r\n",
        "\r\n",
        "def read_label(tf_bytestring):\r\n",
        "    label = tf.io.decode_raw(tf_bytestring, tf.uint8)\r\n",
        "    label = tf.reshape(label, [])\r\n",
        "    label = tf.one_hot(label, 10)\r\n",
        "    return label\r\n",
        "  \r\n",
        "def read_image(tf_bytestring):\r\n",
        "    image = tf.io.decode_raw(tf_bytestring, tf.uint8)\r\n",
        "    image = tf.cast(image, tf.float32)/256.0\r\n",
        "    image = tf.reshape(image, [28*28])\r\n",
        "    return image\r\n",
        "  \r\n",
        "def load_dataset(image_file, label_file):\r\n",
        "    imagedataset = tf.data.FixedLengthRecordDataset(image_file, 28*28, header_bytes=16)\r\n",
        "    imagedataset = imagedataset.map(read_image, num_parallel_calls=16)\r\n",
        "    labelsdataset = tf.data.FixedLengthRecordDataset(label_file, 1, header_bytes=8)\r\n",
        "    labelsdataset = labelsdataset.map(read_label, num_parallel_calls=16)\r\n",
        "    dataset = tf.data.Dataset.zip((imagedataset, labelsdataset))\r\n",
        "    return dataset \r\n",
        "  \r\n",
        "def get_training_dataset(image_file, label_file, batch_size):\r\n",
        "    dataset = load_dataset(image_file, label_file)\r\n",
        "    dataset = dataset.cache()\r\n",
        "    dataset = dataset.shuffle(5000, reshuffle_each_iteration=True)\r\n",
        "    dataset = dataset.repeat()\r\n",
        "    dataset = dataset.batch(batch_size, drop_remainder=True)\r\n",
        "    dataset = dataset.prefetch(AUTO)\r\n",
        "    return dataset\r\n",
        "  \r\n",
        "def get_validation_dataset(image_file, label_file):\r\n",
        "    dataset = load_dataset(image_file, label_file)\r\n",
        "    dataset = dataset.cache()\r\n",
        "    dataset = dataset.batch(10000, drop_remainder=True)\r\n",
        "    dataset = dataset.repeat()\r\n",
        "    return dataset"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nss1N0iImGxq"
      },
      "source": [
        "training_dataset = get_training_dataset(training_images_file, training_labels_file, BATCH_SIZE)\r\n",
        "validation_dataset = get_validation_dataset(validation_images_file, validation_labels_file)\r\n",
        "\r\n",
        "training_input_fn = lambda: get_training_dataset(training_images_file, training_labels_file, BATCH_SIZE)\r\n",
        "validation_input_fn = lambda: get_validation_dataset(validation_images_file, validation_labels_file)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcv50lYMywlh"
      },
      "source": [
        "# Single layer neural net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nyiqkmgIw09K",
        "outputId": "8efe23d8-6505-44c4-8058-d5ddad416fc2"
      },
      "source": [
        "model = tf.keras.Sequential([\r\n",
        "  tf.keras.layers.Input(shape=(28*28, )),\r\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\r\n",
        "])\r\n",
        "\r\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\r\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_2 (Dense)              (None, 10)                7850      \n",
            "=================================================================\n",
            "Total params: 7,850\n",
            "Trainable params: 7,850\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGzSlLbOw7zB",
        "outputId": "38999125-c3bc-4560-96eb-75567a08e4b2"
      },
      "source": [
        "steps_per_epoch = 60000 // BATCH_SIZE\r\n",
        "print(\"Steps per epoch: \", steps_per_epoch)\r\n",
        "\r\n",
        "history = model.fit(training_dataset, steps_per_epoch=steps_per_epoch, epochs=EPOCHS,\r\n",
        "                    validation_data=validation_dataset, validation_steps=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Steps per epoch:  468\n",
            "Epoch 1/10\n",
            "468/468 [==============================] - 5s 8ms/step - loss: 1.6579 - accuracy: 0.5510 - val_loss: 0.8049 - val_accuracy: 0.8359\n",
            "Epoch 2/10\n",
            "468/468 [==============================] - 1s 3ms/step - loss: 0.7660 - accuracy: 0.8335 - val_loss: 0.6052 - val_accuracy: 0.8638\n",
            "Epoch 3/10\n",
            "468/468 [==============================] - 1s 3ms/step - loss: 0.6070 - accuracy: 0.8564 - val_loss: 0.5248 - val_accuracy: 0.8734\n",
            "Epoch 4/10\n",
            "468/468 [==============================] - 1s 3ms/step - loss: 0.5373 - accuracy: 0.8673 - val_loss: 0.4796 - val_accuracy: 0.8809\n",
            "Epoch 5/10\n",
            "468/468 [==============================] - 1s 3ms/step - loss: 0.4914 - accuracy: 0.8760 - val_loss: 0.4502 - val_accuracy: 0.8864\n",
            "Epoch 6/10\n",
            "468/468 [==============================] - 1s 3ms/step - loss: 0.4660 - accuracy: 0.8795 - val_loss: 0.4290 - val_accuracy: 0.8904\n",
            "Epoch 7/10\n",
            "468/468 [==============================] - 1s 3ms/step - loss: 0.4451 - accuracy: 0.8836 - val_loss: 0.4128 - val_accuracy: 0.8930\n",
            "Epoch 8/10\n",
            "468/468 [==============================] - 1s 3ms/step - loss: 0.4310 - accuracy: 0.8858 - val_loss: 0.4000 - val_accuracy: 0.8952\n",
            "Epoch 9/10\n",
            "468/468 [==============================] - 1s 3ms/step - loss: 0.4162 - accuracy: 0.8900 - val_loss: 0.3897 - val_accuracy: 0.8982\n",
            "Epoch 10/10\n",
            "468/468 [==============================] - 2s 3ms/step - loss: 0.4033 - accuracy: 0.8927 - val_loss: 0.3811 - val_accuracy: 0.8997\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eiqcEj_axNbr",
        "outputId": "2b0ca513-592a-474e-bc66-3e44811b42b0"
      },
      "source": [
        "probabilities = model.predict(validation_dataset, steps=1)\r\n",
        "predicted_labels = np.argmax(probabilities, axis=1)\r\n",
        "print(predicted_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[7 2 1 ... 4 8 6]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjoEAaRdyzfq"
      },
      "source": [
        "# Adding layers: Multilayer neural net with sigmoid activations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPuZx5XrxXOe",
        "outputId": "797c7e5c-d6e3-481a-8340-dc7ea86e8272"
      },
      "source": [
        "model = tf.keras.Sequential([\r\n",
        "    tf.keras.layers.Input(shape=(28*28, )),\r\n",
        "    tf.keras.layers.Dense(200, activation='sigmoid'),\r\n",
        "    tf.keras.layers.Dense(60, activation='sigmoid'),\r\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\r\n",
        "])\r\n",
        "\r\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\r\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_6 (Dense)              (None, 200)               157000    \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 60)                12060     \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 10)                610       \n",
            "=================================================================\n",
            "Total params: 169,670\n",
            "Trainable params: 169,670\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kXoJNTNy6jW",
        "outputId": "6fb4f1d0-cfc1-4798-b5b8-b6ae339a9385"
      },
      "source": [
        "steps_per_epoch = 60000 // BATCH_SIZE\r\n",
        "print(\"Steps per epoch: \", steps_per_epoch)\r\n",
        "\r\n",
        "history = model.fit(training_dataset, steps_per_epoch=steps_per_epoch, epochs=EPOCHS,\r\n",
        "                    validation_data=validation_dataset, validation_steps=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Steps per epoch:  468\n",
            "Epoch 1/10\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 2.3608 - accuracy: 0.1398 - val_loss: 2.2455 - val_accuracy: 0.3330\n",
            "Epoch 2/10\n",
            "468/468 [==============================] - 1s 3ms/step - loss: 2.2314 - accuracy: 0.3484 - val_loss: 2.1819 - val_accuracy: 0.5228\n",
            "Epoch 3/10\n",
            "468/468 [==============================] - 2s 3ms/step - loss: 2.1652 - accuracy: 0.5323 - val_loss: 2.0949 - val_accuracy: 0.6242\n",
            "Epoch 4/10\n",
            "468/468 [==============================] - 2s 3ms/step - loss: 2.0720 - accuracy: 0.5978 - val_loss: 1.9718 - val_accuracy: 0.6410\n",
            "Epoch 5/10\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 1.9390 - accuracy: 0.6308 - val_loss: 1.8039 - val_accuracy: 0.6609\n",
            "Epoch 6/10\n",
            "468/468 [==============================] - 2s 3ms/step - loss: 1.7647 - accuracy: 0.6545 - val_loss: 1.6085 - val_accuracy: 0.6791\n",
            "Epoch 7/10\n",
            "468/468 [==============================] - 2s 3ms/step - loss: 1.5698 - accuracy: 0.6786 - val_loss: 1.4158 - val_accuracy: 0.7123\n",
            "Epoch 8/10\n",
            "468/468 [==============================] - 2s 3ms/step - loss: 1.3824 - accuracy: 0.7073 - val_loss: 1.2473 - val_accuracy: 0.7395\n",
            "Epoch 9/10\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 1.2238 - accuracy: 0.7337 - val_loss: 1.1065 - val_accuracy: 0.7615\n",
            "Epoch 10/10\n",
            "468/468 [==============================] - 2s 3ms/step - loss: 1.0876 - accuracy: 0.7566 - val_loss: 0.9926 - val_accuracy: 0.7764\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6pi9qvL2HQl"
      },
      "source": [
        "# Special care for deep networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cF4Cs6eSzBWx",
        "outputId": "808dbca9-3c33-4dba-804a-ecf6184eb73a"
      },
      "source": [
        "model = tf.keras.Sequential([\r\n",
        "    tf.keras.layers.Input(shape=(28*28, )),\r\n",
        "    tf.keras.layers.Dense(200, activation='relu'),\r\n",
        "    tf.keras.layers.Dense(60, activation='relu'),\r\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\r\n",
        "])\r\n",
        "\r\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\r\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_9 (Dense)              (None, 200)               157000    \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 60)                12060     \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 10)                610       \n",
            "=================================================================\n",
            "Total params: 169,670\n",
            "Trainable params: 169,670\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-iU-QyY2fmb",
        "outputId": "94ffa930-03f7-4d6a-be7c-360e8e90590a"
      },
      "source": [
        "steps_per_epoch = 60000 // BATCH_SIZE\r\n",
        "print(\"Steps per epoch: \", steps_per_epoch)\r\n",
        "\r\n",
        "history = model.fit(training_dataset, steps_per_epoch=steps_per_epoch, epochs=EPOCHS,\r\n",
        "                    validation_data=validation_dataset, validation_steps=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Steps per epoch:  468\n",
            "Epoch 1/10\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.5370 - accuracy: 0.8467 - val_loss: 0.1516 - val_accuracy: 0.9557\n",
            "Epoch 2/10\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.1283 - accuracy: 0.9617 - val_loss: 0.1220 - val_accuracy: 0.9616\n",
            "Epoch 3/10\n",
            "468/468 [==============================] - 2s 3ms/step - loss: 0.0850 - accuracy: 0.9743 - val_loss: 0.0968 - val_accuracy: 0.9702\n",
            "Epoch 4/10\n",
            "468/468 [==============================] - 1s 3ms/step - loss: 0.0640 - accuracy: 0.9807 - val_loss: 0.0788 - val_accuracy: 0.9750\n",
            "Epoch 5/10\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.0476 - accuracy: 0.9863 - val_loss: 0.0823 - val_accuracy: 0.9735\n",
            "Epoch 6/10\n",
            "468/468 [==============================] - 2s 3ms/step - loss: 0.0374 - accuracy: 0.9890 - val_loss: 0.0829 - val_accuracy: 0.9755\n",
            "Epoch 7/10\n",
            "468/468 [==============================] - 2s 3ms/step - loss: 0.0273 - accuracy: 0.9915 - val_loss: 0.0728 - val_accuracy: 0.9781\n",
            "Epoch 8/10\n",
            "468/468 [==============================] - 2s 3ms/step - loss: 0.0239 - accuracy: 0.9925 - val_loss: 0.0737 - val_accuracy: 0.9784\n",
            "Epoch 9/10\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.0197 - accuracy: 0.9936 - val_loss: 0.0784 - val_accuracy: 0.9777\n",
            "Epoch 10/10\n",
            "468/468 [==============================] - 2s 3ms/step - loss: 0.0162 - accuracy: 0.9954 - val_loss: 0.0851 - val_accuracy: 0.9769\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gt4Sv7l_2wNP"
      },
      "source": [
        "# Learning rate decay"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMNXRNUA2i-2",
        "outputId": "98913e42-25a9-49a7-b5ef-d61e4d552494"
      },
      "source": [
        "model = tf.keras.Sequential([\r\n",
        "    tf.keras.layers.Input(shape=(28*28, )),\r\n",
        "    tf.keras.layers.Dense(200, activation='relu'),\r\n",
        "    tf.keras.layers.Dense(60, activation='relu'),\r\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\r\n",
        "])\r\n",
        "\r\n",
        "optimizer = tf.keras.optimizers.Adam(lr=0.01)\r\n",
        "\r\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\r\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_12 (Dense)             (None, 200)               157000    \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 60)                12060     \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 10)                610       \n",
            "=================================================================\n",
            "Total params: 169,670\n",
            "Trainable params: 169,670\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYgyFw4V2-zX",
        "outputId": "07e02e21-f562-4065-c10f-c98cf97080de"
      },
      "source": [
        "steps_per_epoch = 60000 // BATCH_SIZE\r\n",
        "print(\"Steps per epoch: \", steps_per_epoch)\r\n",
        "\r\n",
        "def lr_decay(epoch):\r\n",
        "  return 0.01 * math.pow(0.6, epoch)\r\n",
        "\r\n",
        "lr_decay_callback = tf.keras.callbacks.LearningRateScheduler(lr_decay, verbose=True)\r\n",
        "\r\n",
        "history = model.fit(training_dataset, steps_per_epoch=steps_per_epoch, epochs=EPOCHS, \r\n",
        "                    validation_data=validation_dataset, validation_steps=1, \r\n",
        "                    callbacks=[lr_decay_callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Steps per epoch:  468\n",
            "Epoch 1/10\n",
            "\n",
            "Epoch 00001: LearningRateScheduler reducing learning rate to 0.01.\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.0522 - accuracy: 0.9856 - val_loss: 0.1299 - val_accuracy: 0.9747\n",
            "Epoch 2/10\n",
            "\n",
            "Epoch 00002: LearningRateScheduler reducing learning rate to 0.006.\n",
            "468/468 [==============================] - 2s 3ms/step - loss: 0.0228 - accuracy: 0.9931 - val_loss: 0.1092 - val_accuracy: 0.9795\n",
            "Epoch 3/10\n",
            "\n",
            "Epoch 00003: LearningRateScheduler reducing learning rate to 0.0036.\n",
            "468/468 [==============================] - 2s 3ms/step - loss: 0.0091 - accuracy: 0.9970 - val_loss: 0.1080 - val_accuracy: 0.9806\n",
            "Epoch 4/10\n",
            "\n",
            "Epoch 00004: LearningRateScheduler reducing learning rate to 0.0021599999999999996.\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.1115 - val_accuracy: 0.9815\n",
            "Epoch 5/10\n",
            "\n",
            "Epoch 00005: LearningRateScheduler reducing learning rate to 0.001296.\n",
            "468/468 [==============================] - 2s 3ms/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 0.1131 - val_accuracy: 0.9817\n",
            "Epoch 6/10\n",
            "\n",
            "Epoch 00006: LearningRateScheduler reducing learning rate to 0.0007775999999999998.\n",
            "468/468 [==============================] - 2s 3ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.1148 - val_accuracy: 0.9824\n",
            "Epoch 7/10\n",
            "\n",
            "Epoch 00007: LearningRateScheduler reducing learning rate to 0.0004665599999999999.\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.1158 - val_accuracy: 0.9825\n",
            "Epoch 8/10\n",
            "\n",
            "Epoch 00008: LearningRateScheduler reducing learning rate to 0.00027993599999999994.\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.1169 - val_accuracy: 0.9827\n",
            "Epoch 9/10\n",
            "\n",
            "Epoch 00009: LearningRateScheduler reducing learning rate to 0.00016796159999999993.\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.1176 - val_accuracy: 0.9827\n",
            "Epoch 10/10\n",
            "\n",
            "Epoch 00010: LearningRateScheduler reducing learning rate to 0.00010077695999999997.\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.1181 - val_accuracy: 0.9827\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4mC2Rtg4hSb"
      },
      "source": [
        "# Dropout / Overfitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QjdZrPz43Deo",
        "outputId": "922156eb-46ea-42b2-e04f-7af717d83580"
      },
      "source": [
        "model = tf.keras.Sequential([\r\n",
        "    tf.keras.layers.Input(shape=(28*28, )),\r\n",
        "    tf.keras.layers.Dense(200, activation='relu'),\r\n",
        "    tf.keras.layers.Dropout(0.25),\r\n",
        "    tf.keras.layers.Dense(100, activation='relu'),\r\n",
        "    tf.keras.layers.Dropout(0.25),\r\n",
        "    tf.keras.layers.Dense(60, activation='relu'),\r\n",
        "    tf.keras.layers.Dropout(0.25),\r\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\r\n",
        "])\r\n",
        "\r\n",
        "optimizer = tf.keras.optimizers.Adam(lr=0.01)\r\n",
        "\r\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\r\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_15 (Dense)             (None, 200)               157000    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 100)               20100     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 60)                6060      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 60)                0         \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 10)                610       \n",
            "=================================================================\n",
            "Total params: 183,770\n",
            "Trainable params: 183,770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwFhUw4o4nMl",
        "outputId": "93dbccb1-e9f3-4e4c-cd16-8f2caccff918"
      },
      "source": [
        "steps_per_epoch = 60000 // BATCH_SIZE\r\n",
        "print(\"Steps per epoch: \", steps_per_epoch)\r\n",
        "\r\n",
        "def lr_decay(epoch):\r\n",
        "  return 0.01 * math.pow(0.6, epoch)\r\n",
        "\r\n",
        "lr_decay_callback = tf.keras.callbacks.LearningRateScheduler(lr_decay, verbose=True)\r\n",
        "\r\n",
        "history = model.fit(training_dataset, steps_per_epoch=steps_per_epoch, epochs=EPOCHS, \r\n",
        "                    validation_data=validation_dataset, validation_steps=1, \r\n",
        "                    callbacks=[lr_decay_callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Steps per epoch:  468\n",
            "Epoch 1/10\n",
            "\n",
            "Epoch 00001: LearningRateScheduler reducing learning rate to 0.01.\n",
            "468/468 [==============================] - 2s 5ms/step - loss: 0.6114 - accuracy: 0.8132 - val_loss: 0.1909 - val_accuracy: 0.9499\n",
            "Epoch 2/10\n",
            "\n",
            "Epoch 00002: LearningRateScheduler reducing learning rate to 0.006.\n",
            "468/468 [==============================] - 2s 3ms/step - loss: 0.2408 - accuracy: 0.9347 - val_loss: 0.1447 - val_accuracy: 0.9605\n",
            "Epoch 3/10\n",
            "\n",
            "Epoch 00003: LearningRateScheduler reducing learning rate to 0.0036.\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.1660 - accuracy: 0.9544 - val_loss: 0.1142 - val_accuracy: 0.9690\n",
            "Epoch 4/10\n",
            "\n",
            "Epoch 00004: LearningRateScheduler reducing learning rate to 0.0021599999999999996.\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.1320 - accuracy: 0.9640 - val_loss: 0.1047 - val_accuracy: 0.9690\n",
            "Epoch 5/10\n",
            "\n",
            "Epoch 00005: LearningRateScheduler reducing learning rate to 0.001296.\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.1151 - accuracy: 0.9687 - val_loss: 0.0983 - val_accuracy: 0.9725\n",
            "Epoch 6/10\n",
            "\n",
            "Epoch 00006: LearningRateScheduler reducing learning rate to 0.0007775999999999998.\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.1000 - accuracy: 0.9722 - val_loss: 0.0905 - val_accuracy: 0.9751\n",
            "Epoch 7/10\n",
            "\n",
            "Epoch 00007: LearningRateScheduler reducing learning rate to 0.0004665599999999999.\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.0932 - accuracy: 0.9728 - val_loss: 0.0890 - val_accuracy: 0.9760\n",
            "Epoch 8/10\n",
            "\n",
            "Epoch 00008: LearningRateScheduler reducing learning rate to 0.00027993599999999994.\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.0833 - accuracy: 0.9765 - val_loss: 0.0867 - val_accuracy: 0.9760\n",
            "Epoch 9/10\n",
            "\n",
            "Epoch 00009: LearningRateScheduler reducing learning rate to 0.00016796159999999993.\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.0822 - accuracy: 0.9763 - val_loss: 0.0871 - val_accuracy: 0.9770\n",
            "Epoch 10/10\n",
            "\n",
            "Epoch 00010: LearningRateScheduler reducing learning rate to 0.00010077695999999997.\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.0806 - accuracy: 0.9772 - val_loss: 0.0867 - val_accuracy: 0.9773\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DGTDAd67ryt"
      },
      "source": [
        "# A convolutional network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xI90pcbL6oSJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a5a60a3-d74b-4618-a07c-a687062b6d45"
      },
      "source": [
        "model = tf.keras.Sequential([\r\n",
        "    tf.keras.layers.Reshape(input_shape=(28*28,), target_shape=(28, 28, 1)),\r\n",
        "    tf.keras.layers.Conv2D(kernel_size=3, filters=12, padding='same', activation='relu'),\r\n",
        "    tf.keras.layers.Conv2D(kernel_size=6, filters=24, padding='same', activation='relu', strides=2),\r\n",
        "    tf.keras.layers.Conv2D(kernel_size=6, filters=32, padding='same', activation='relu', strides=2),\r\n",
        "    tf.keras.layers.Flatten(),\r\n",
        "    tf.keras.layers.Dense(200, activation='relu'),\r\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\r\n",
        "])\r\n",
        "\r\n",
        "optimizer = tf.keras.optimizers.Adam(lr=0.01)\r\n",
        "\r\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\r\n",
        "model.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "reshape (Reshape)            (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 28, 28, 12)        120       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 14, 14, 24)        10392     \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 7, 7, 32)          27680     \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1568)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 200)               313800    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                2010      \n",
            "=================================================================\n",
            "Total params: 354,002\n",
            "Trainable params: 354,002\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIUblQKiKOob",
        "outputId": "49f518a8-cfe6-4ad2-e001-eb5a7b49a2fd"
      },
      "source": [
        "steps_per_epoch = 60000 // BATCH_SIZE\r\n",
        "print(\"Steps per epoch: \", steps_per_epoch)\r\n",
        "\r\n",
        "def lr_decay(epoch):\r\n",
        "  return 0.01 * math.pow(0.6, epoch)\r\n",
        "\r\n",
        "lr_decay_callback = tf.keras.callbacks.LearningRateScheduler(lr_decay, verbose=True)\r\n",
        "\r\n",
        "history = model.fit(training_dataset, steps_per_epoch=steps_per_epoch, epochs=EPOCHS, \r\n",
        "                    validation_data=validation_dataset, validation_steps=1, \r\n",
        "                    callbacks=[lr_decay_callback])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Steps per epoch:  468\n",
            "Epoch 1/10\n",
            "\n",
            "Epoch 00001: LearningRateScheduler reducing learning rate to 0.01.\n",
            "468/468 [==============================] - 11s 10ms/step - loss: 0.4629 - accuracy: 0.8441 - val_loss: 0.0709 - val_accuracy: 0.9775\n",
            "Epoch 2/10\n",
            "\n",
            "Epoch 00002: LearningRateScheduler reducing learning rate to 0.006.\n",
            "468/468 [==============================] - 2s 5ms/step - loss: 0.0534 - accuracy: 0.9838 - val_loss: 0.0460 - val_accuracy: 0.9853\n",
            "Epoch 3/10\n",
            "\n",
            "Epoch 00003: LearningRateScheduler reducing learning rate to 0.0036.\n",
            "468/468 [==============================] - 3s 5ms/step - loss: 0.0295 - accuracy: 0.9913 - val_loss: 0.0385 - val_accuracy: 0.9882\n",
            "Epoch 4/10\n",
            "\n",
            "Epoch 00004: LearningRateScheduler reducing learning rate to 0.0021599999999999996.\n",
            "468/468 [==============================] - 3s 5ms/step - loss: 0.0158 - accuracy: 0.9949 - val_loss: 0.0372 - val_accuracy: 0.9890\n",
            "Epoch 5/10\n",
            "\n",
            "Epoch 00005: LearningRateScheduler reducing learning rate to 0.001296.\n",
            "468/468 [==============================] - 2s 5ms/step - loss: 0.0089 - accuracy: 0.9969 - val_loss: 0.0397 - val_accuracy: 0.9894\n",
            "Epoch 6/10\n",
            "\n",
            "Epoch 00006: LearningRateScheduler reducing learning rate to 0.0007775999999999998.\n",
            "468/468 [==============================] - 3s 5ms/step - loss: 0.0049 - accuracy: 0.9986 - val_loss: 0.0406 - val_accuracy: 0.9904\n",
            "Epoch 7/10\n",
            "\n",
            "Epoch 00007: LearningRateScheduler reducing learning rate to 0.0004665599999999999.\n",
            "468/468 [==============================] - 3s 5ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.0433 - val_accuracy: 0.9904\n",
            "Epoch 8/10\n",
            "\n",
            "Epoch 00008: LearningRateScheduler reducing learning rate to 0.00027993599999999994.\n",
            "468/468 [==============================] - 3s 5ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.0444 - val_accuracy: 0.9903\n",
            "Epoch 9/10\n",
            "\n",
            "Epoch 00009: LearningRateScheduler reducing learning rate to 0.00016796159999999993.\n",
            "468/468 [==============================] - 2s 5ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0454 - val_accuracy: 0.9906\n",
            "Epoch 10/10\n",
            "\n",
            "Epoch 00010: LearningRateScheduler reducing learning rate to 0.00010077695999999997.\n",
            "468/468 [==============================] - 3s 5ms/step - loss: 8.4106e-04 - accuracy: 0.9999 - val_loss: 0.0461 - val_accuracy: 0.9905\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbIpLxwuMib-"
      },
      "source": [
        "# Dropout again"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3USW0TimMThG",
        "outputId": "99ff84e8-1709-4b40-edd6-cc17941454ce"
      },
      "source": [
        "model = tf.keras.Sequential([\r\n",
        "    tf.keras.layers.Reshape(input_shape=(28*28,), target_shape=(28, 28, 1)),\r\n",
        "    tf.keras.layers.Conv2D(kernel_size=3, filters=12, padding='same', activation='relu'),\r\n",
        "    tf.keras.layers.Conv2D(kernel_size=6, filters=24, padding='same', activation='relu', strides=2),\r\n",
        "    tf.keras.layers.Conv2D(kernel_size=6, filters=32, padding='same', activation='relu', strides=2),\r\n",
        "    tf.keras.layers.Flatten(),\r\n",
        "    tf.keras.layers.Dense(200, activation='relu'),\r\n",
        "    tf.keras.layers.Dropout(0.4),\r\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\r\n",
        "])\r\n",
        "\r\n",
        "optimizer = tf.keras.optimizers.Adam(lr=0.01)\r\n",
        "\r\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\r\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "reshape_1 (Reshape)          (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 28, 28, 12)        120       \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 14, 14, 24)        10392     \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 7, 7, 32)          27680     \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 1568)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 200)               313800    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                2010      \n",
            "=================================================================\n",
            "Total params: 354,002\n",
            "Trainable params: 354,002\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UcfFVhRMllp",
        "outputId": "2ca41380-cc9d-4efb-8969-6e08efbf6690"
      },
      "source": [
        "steps_per_epoch = 60000 // BATCH_SIZE\r\n",
        "print(\"Steps per epoch: \", steps_per_epoch)\r\n",
        "\r\n",
        "def lr_decay(epoch):\r\n",
        "  return 0.01 * math.pow(0.6, epoch)\r\n",
        "\r\n",
        "lr_decay_callback = tf.keras.callbacks.LearningRateScheduler(lr_decay, verbose=True)\r\n",
        "\r\n",
        "history = model.fit(training_dataset, steps_per_epoch=steps_per_epoch, epochs=EPOCHS, \r\n",
        "                    validation_data=validation_dataset, validation_steps=1, \r\n",
        "                    callbacks=[lr_decay_callback])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Steps per epoch:  468\n",
            "Epoch 1/10\n",
            "\n",
            "Epoch 00001: LearningRateScheduler reducing learning rate to 0.01.\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.3379 - accuracy: 0.8915 - val_loss: 0.0661 - val_accuracy: 0.9793\n",
            "Epoch 2/10\n",
            "\n",
            "Epoch 00002: LearningRateScheduler reducing learning rate to 0.006.\n",
            "468/468 [==============================] - 2s 5ms/step - loss: 0.0718 - accuracy: 0.9794 - val_loss: 0.0476 - val_accuracy: 0.9871\n",
            "Epoch 3/10\n",
            "\n",
            "Epoch 00003: LearningRateScheduler reducing learning rate to 0.0036.\n",
            "468/468 [==============================] - 3s 5ms/step - loss: 0.0370 - accuracy: 0.9895 - val_loss: 0.0334 - val_accuracy: 0.9903\n",
            "Epoch 4/10\n",
            "\n",
            "Epoch 00004: LearningRateScheduler reducing learning rate to 0.0021599999999999996.\n",
            "468/468 [==============================] - 3s 5ms/step - loss: 0.0206 - accuracy: 0.9937 - val_loss: 0.0251 - val_accuracy: 0.9915\n",
            "Epoch 5/10\n",
            "\n",
            "Epoch 00005: LearningRateScheduler reducing learning rate to 0.001296.\n",
            "468/468 [==============================] - 3s 5ms/step - loss: 0.0113 - accuracy: 0.9964 - val_loss: 0.0263 - val_accuracy: 0.9917\n",
            "Epoch 6/10\n",
            "\n",
            "Epoch 00006: LearningRateScheduler reducing learning rate to 0.0007775999999999998.\n",
            "468/468 [==============================] - 3s 5ms/step - loss: 0.0071 - accuracy: 0.9976 - val_loss: 0.0279 - val_accuracy: 0.9920\n",
            "Epoch 7/10\n",
            "\n",
            "Epoch 00007: LearningRateScheduler reducing learning rate to 0.0004665599999999999.\n",
            "468/468 [==============================] - 3s 5ms/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 0.0282 - val_accuracy: 0.9922\n",
            "Epoch 8/10\n",
            "\n",
            "Epoch 00008: LearningRateScheduler reducing learning rate to 0.00027993599999999994.\n",
            "468/468 [==============================] - 2s 5ms/step - loss: 0.0039 - accuracy: 0.9990 - val_loss: 0.0286 - val_accuracy: 0.9922\n",
            "Epoch 9/10\n",
            "\n",
            "Epoch 00009: LearningRateScheduler reducing learning rate to 0.00016796159999999993.\n",
            "468/468 [==============================] - 3s 5ms/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.0299 - val_accuracy: 0.9919\n",
            "Epoch 10/10\n",
            "\n",
            "Epoch 00010: LearningRateScheduler reducing learning rate to 0.00010077695999999997.\n",
            "468/468 [==============================] - 3s 5ms/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.0290 - val_accuracy: 0.9922\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7p5mTB4uNP33"
      },
      "source": [
        "# Batch normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zngDtE3kM0cO",
        "outputId": "82d22a5a-020e-4922-a32d-646ae9f59a50"
      },
      "source": [
        "model = tf.keras.Sequential([\r\n",
        "    tf.keras.layers.Reshape(input_shape=(28*28,), target_shape=(28, 28, 1)),\r\n",
        "\r\n",
        "    tf.keras.layers.Conv2D(kernel_size=3, filters=12, padding='same', use_bias=False),\r\n",
        "    tf.keras.layers.BatchNormalization(scale=False, center=True),\r\n",
        "    tf.keras.layers.Activation('relu'),\r\n",
        "\r\n",
        "    tf.keras.layers.Conv2D(kernel_size=6, filters=24, padding='same', strides=2, use_bias=False),\r\n",
        "    tf.keras.layers.BatchNormalization(scale=False, center=True),\r\n",
        "    tf.keras.layers.Activation('relu'),\r\n",
        "\r\n",
        "    tf.keras.layers.Conv2D(kernel_size=6, filters=32, padding='same', strides=2, use_bias=False),\r\n",
        "    tf.keras.layers.BatchNormalization(scale=False, center=True),\r\n",
        "    tf.keras.layers.Activation('relu'),\r\n",
        "\r\n",
        "    tf.keras.layers.Flatten(),\r\n",
        "\r\n",
        "    tf.keras.layers.Dense(200, use_bias=False),\r\n",
        "    tf.keras.layers.BatchNormalization(scale=False, center=True),\r\n",
        "    tf.keras.layers.Activation('relu'),\r\n",
        "\r\n",
        "    tf.keras.layers.Dropout(0.4),\r\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\r\n",
        "])\r\n",
        "\r\n",
        "optimizer = tf.keras.optimizers.Adam(lr=0.01)\r\n",
        "\r\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\r\n",
        "model.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "reshape_2 (Reshape)          (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 28, 28, 12)        108       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 28, 28, 12)        36        \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 28, 28, 12)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 14, 14, 24)        10368     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 14, 14, 24)        72        \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 14, 14, 24)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 7, 7, 32)          27648     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 7, 7, 32)          96        \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 7, 7, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 1568)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 200)               313600    \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 200)               600       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                2010      \n",
            "=================================================================\n",
            "Total params: 354,538\n",
            "Trainable params: 354,002\n",
            "Non-trainable params: 536\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgRlOoBfOPfU",
        "outputId": "597d0e80-f716-4303-beed-b95b3de8d8c2"
      },
      "source": [
        "steps_per_epoch = 60000 // BATCH_SIZE\r\n",
        "print(\"Steps per epoch: \", steps_per_epoch)\r\n",
        "\r\n",
        "def lr_decay(epoch):\r\n",
        "  return 0.01 * math.pow(0.6, epoch)\r\n",
        "\r\n",
        "lr_decay_callback = tf.keras.callbacks.LearningRateScheduler(lr_decay, verbose=True)\r\n",
        "\r\n",
        "history = model.fit(training_dataset, steps_per_epoch=steps_per_epoch, epochs=EPOCHS, \r\n",
        "                    validation_data=validation_dataset, validation_steps=1, \r\n",
        "                    callbacks=[lr_decay_callback])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Steps per epoch:  468\n",
            "Epoch 1/10\n",
            "\n",
            "Epoch 00001: LearningRateScheduler reducing learning rate to 0.01.\n",
            "468/468 [==============================] - 4s 7ms/step - loss: 0.2585 - accuracy: 0.9208 - val_loss: 0.0548 - val_accuracy: 0.9833\n",
            "Epoch 2/10\n",
            "\n",
            "Epoch 00002: LearningRateScheduler reducing learning rate to 0.006.\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.0514 - accuracy: 0.9847 - val_loss: 0.0372 - val_accuracy: 0.9886\n",
            "Epoch 3/10\n",
            "\n",
            "Epoch 00003: LearningRateScheduler reducing learning rate to 0.0036.\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.0316 - accuracy: 0.9903 - val_loss: 0.0271 - val_accuracy: 0.9914\n",
            "Epoch 4/10\n",
            "\n",
            "Epoch 00004: LearningRateScheduler reducing learning rate to 0.0021599999999999996.\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.0190 - accuracy: 0.9941 - val_loss: 0.0224 - val_accuracy: 0.9929\n",
            "Epoch 5/10\n",
            "\n",
            "Epoch 00005: LearningRateScheduler reducing learning rate to 0.001296.\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.0134 - accuracy: 0.9957 - val_loss: 0.0192 - val_accuracy: 0.9944\n",
            "Epoch 6/10\n",
            "\n",
            "Epoch 00006: LearningRateScheduler reducing learning rate to 0.0007775999999999998.\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.0100 - accuracy: 0.9972 - val_loss: 0.0197 - val_accuracy: 0.9938\n",
            "Epoch 7/10\n",
            "\n",
            "Epoch 00007: LearningRateScheduler reducing learning rate to 0.0004665599999999999.\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.0073 - accuracy: 0.9978 - val_loss: 0.0192 - val_accuracy: 0.9942\n",
            "Epoch 8/10\n",
            "\n",
            "Epoch 00008: LearningRateScheduler reducing learning rate to 0.00027993599999999994.\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.0050 - accuracy: 0.9987 - val_loss: 0.0198 - val_accuracy: 0.9940\n",
            "Epoch 9/10\n",
            "\n",
            "Epoch 00009: LearningRateScheduler reducing learning rate to 0.00016796159999999993.\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.0056 - accuracy: 0.9985 - val_loss: 0.0199 - val_accuracy: 0.9935\n",
            "Epoch 10/10\n",
            "\n",
            "Epoch 00010: LearningRateScheduler reducing learning rate to 0.00010077695999999997.\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.0045 - accuracy: 0.9990 - val_loss: 0.0193 - val_accuracy: 0.9937\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}